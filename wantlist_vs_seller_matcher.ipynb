{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Following code iterates through the inventory of seller and matches it in a more enhanced way:\n",
    "1. fetching the master IDs from your wantlist via API\n",
    "2. fetching data from seller's inventory (seller to be specified)\n",
    "3. fetching all the releases(versions) of all master releases of the matched artists\n",
    "4. matching wantlist & seller by checking every single release version\n",
    "\n",
    "## How to execute the code :\n",
    "1. Clone this repository\n",
    "2. Log in to the discogs.com and get the personal API Token\n",
    "3. Add the API Token & Seller's username to section BELOW (name of a shop you want to fetch data from) to the related variables in Jupiter notebook\n",
    "4. Execute the notebook and wait for your results!\n",
    "\n",
    "### Limitations: Discogs does not allow >100 api calls per second. Big sellers might take a few minutes to load"
   ],
   "id": "b40e57fd015a2f2c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## YOUR INPUT",
   "id": "56631511a72b8695"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T10:37:49.937662Z",
     "start_time": "2024-12-22T10:37:49.935698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Replace with your API Disocgs Token \n",
    "my_user_token = 'YOUR_API_TOKEN'\n",
    "\n",
    "# Replace with the actual seller's username\n",
    "seller_username = \"YOUR_SELLER_USERNAME\""
   ],
   "id": "aa15468b858a5834",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 0: User Initiation + Seller Username",
   "id": "aa6a33cdb9e8c880"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T10:37:50.867170Z",
     "start_time": "2024-12-22T10:37:49.969148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install python3-discogs-client\n",
    "import discogs_client\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "import time\n",
    "import concurrent.futures"
   ],
   "id": "963d2231c7932fe1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python3-discogs-client in /Users/borysarkhypenko/.pyenv/versions/3.11.2/lib/python3.11/site-packages (2.7.1)\r\n",
      "Requirement already satisfied: requests in /Users/borysarkhypenko/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from python3-discogs-client) (2.32.3)\r\n",
      "Requirement already satisfied: oauthlib in /Users/borysarkhypenko/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from python3-discogs-client) (3.2.2)\r\n",
      "Requirement already satisfied: python-dateutil in /Users/borysarkhypenko/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from python3-discogs-client) (2.9.0.post0)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/borysarkhypenko/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from python-dateutil->python3-discogs-client) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/borysarkhypenko/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->python3-discogs-client) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/borysarkhypenko/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->python3-discogs-client) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/borysarkhypenko/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->python3-discogs-client) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/borysarkhypenko/.pyenv/versions/3.11.2/lib/python3.11/site-packages (from requests->python3-discogs-client) (2024.7.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T10:37:51.413866Z",
     "start_time": "2024-12-22T10:37:50.868556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d = discogs_client.Client('discogs application project', user_token=my_user_token)\n",
    "\n",
    "me = d.identity()\n",
    "wantlist = me.wantlist\n",
    "\n",
    "# Set headers with authentication\n",
    "headers = {\n",
    "    'Authorization': f'Discogs token={my_user_token}',\n",
    "    'User-Agent': 'Discogs-Inventory-App'\n",
    "}\n"
   ],
   "id": "51b512808d6d8e9c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 1: Fetching MasterID+Artist from Wantlist",
   "id": "31b56ef7e698b45c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T10:37:57.766177Z",
     "start_time": "2024-12-22T10:37:51.415197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to process a release from the wantlist\n",
    "def process_release(item):\n",
    "    release = item.release  # Get the release object\n",
    "    master_id = None\n",
    "    artists = set()\n",
    "    \n",
    "    # Check and collect master ID if it exists\n",
    "    if release.master:\n",
    "        master_id = release.master.id\n",
    "    \n",
    "    # Collect artist names\n",
    "    artist_names = []\n",
    "    for artist in release.artists:\n",
    "        # Access the name and join fields directly\n",
    "        if hasattr(artist, 'join') and artist.join:\n",
    "            artist_names.append(f\"{artist.name} {artist.join}\")\n",
    "        else:\n",
    "            artist_names.append(artist.name)\n",
    "    \n",
    "    # Combine artist names into a single string and add to the set\n",
    "    artists.add(\" \".join(artist_names))\n",
    "    \n",
    "    return master_id, artists\n",
    "\n",
    "# Collecting unique master IDs and artists concurrently\n",
    "def fetch_wantlist_data_concurrently(wantlist):\n",
    "    wantlist_master_ids = set()\n",
    "    wantlist_artists = set()\n",
    "\n",
    "    # Use ThreadPoolExecutor to process releases concurrently\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        # Submit all releases to the thread pool\n",
    "        future_to_release = {executor.submit(process_release, item): item for item in wantlist}\n",
    "        \n",
    "        # Process the results as they complete\n",
    "        for future in concurrent.futures.as_completed(future_to_release):\n",
    "            try:\n",
    "                master_id, artists = future.result()\n",
    "\n",
    "                # Add master ID to the set if it exists\n",
    "                if master_id:\n",
    "                    wantlist_master_ids.add(master_id)\n",
    "\n",
    "                # Add all artist names to the set\n",
    "                wantlist_artists.update(artists)\n",
    "\n",
    "            except Exception as exc:\n",
    "                print(f\"Error processing release: {exc}\")\n",
    "\n",
    "    return wantlist_master_ids, wantlist_artists\n",
    "\n",
    "wantlist_master_ids, wantlist_artists = fetch_wantlist_data_concurrently(me.wantlist)\n",
    "\n",
    "print(\"# of unique Master IDs in your wantlist:\",len(wantlist_master_ids))\n",
    "print(\"# of unique Artists in your wantlist:\",len(wantlist_artists))"
   ],
   "id": "8ea24b1b16e00eef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique Master IDs in your wantlist: 159\n",
      "# of unique Artists in your wantlist: 140\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Fetching Release+Artist from Seller",
   "id": "4084eb102e445f0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T10:38:03.744722Z",
     "start_time": "2024-12-22T10:37:57.767909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "time.sleep(3)\n",
    "\n",
    "items_per_page = 100  # Max number of items per page to be fetched\n",
    "\n",
    "def fetch_inventory_page(page, seller_username, items_per_page, headers):\n",
    "    \"\"\"Fetch a single page of inventory from the Discogs API.\"\"\"\n",
    "    url = f\"https://api.discogs.com/users/{seller_username}/inventory?per_page={items_per_page}&page={page}&sort=artist&sort_order=asc\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        remaining_requests = int(response.headers.get('X-Discogs-Ratelimit-Remaining', 60))\n",
    "        reset_time = int(response.headers.get('X-Discogs-Ratelimit-Reset', 60))\n",
    "        return response.json(), remaining_requests, reset_time\n",
    "    else:\n",
    "        print(f\"Error fetching page {page}: {response.status_code}, {response.text}\")\n",
    "        return None, 0, 60  # Default values in case of error\n",
    "\n",
    "def adaptive_sleep(remaining_requests, reset_time):\n",
    "    \"\"\"Calculate adaptive sleep time based on remaining requests and reset time.\"\"\"\n",
    "    if remaining_requests > 0:\n",
    "        return reset_time / remaining_requests\n",
    "    else:\n",
    "        return reset_time\n",
    "\n",
    "# Set to store unique artist names and release IDs\n",
    "unique_artists = set()\n",
    "unique_releases = set()\n",
    "artists_and_releases_and_items = set()\n",
    "\n",
    "# Progress tracking\n",
    "total_checked_items = 0  # To keep track of how many items we've processed\n",
    "\n",
    "\n",
    "# First, get the first page to find the total number of items\n",
    "inventory_data, remaining_requests, reset_time = fetch_inventory_page(1, seller_username, items_per_page, headers)\n",
    "if inventory_data:\n",
    "    total_items = inventory_data['pagination']['items']\n",
    "    total_pages = inventory_data['pagination']['pages']\n",
    "    print(f\"Total items: {total_items}, Total pages: {total_pages}\")\n",
    "    \n",
    "    # Add artists and releases from the first page\n",
    "    for item in inventory_data['listings']:\n",
    "        artist_name = item[\"release\"].get(\"artist\")\n",
    "        release_id = item[\"release\"].get(\"id\")\n",
    "        item_id = item[\"id\"]\n",
    "        if artist_name and release_id:\n",
    "            unique_artists.add(artist_name)\n",
    "            unique_releases.add(release_id)\n",
    "            artists_and_releases_and_items.add((artist_name, release_id, item_id))\n",
    "        \n",
    "        total_checked_items += 1  # Update total checked items after processing\n",
    "\n",
    "    # Print the progress\n",
    "    print(f\"Checked {total_checked_items} items out of {total_items}\")\n",
    "\n",
    "    # Fetch the rest of the pages with adaptive sleep and limiting concurrency\n",
    "    pages_to_process = total_pages - 1  # Already fetched page 1\n",
    "    current_page = 2\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        while pages_to_process > 0:\n",
    "            # Determine the number of pages to fetch in this batch\n",
    "            pages_in_batch = min(remaining_requests, pages_to_process)  # Use remaining requests\n",
    "            \n",
    "            futures = [executor.submit(fetch_inventory_page, page, seller_username, items_per_page, headers)\n",
    "                       for page in range(current_page, current_page + pages_in_batch)]\n",
    "            \n",
    "            for future in as_completed(futures):\n",
    "                inventory_data, remaining_requests, reset_time = future.result()\n",
    "                if inventory_data and 'listings' in inventory_data:\n",
    "                    for item in inventory_data['listings']:\n",
    "                        artist_name = item[\"release\"].get(\"artist\")\n",
    "                        release_id = item[\"release\"].get(\"id\")\n",
    "                        item_id = item[\"id\"]\n",
    "                        if artist_name and release_id:\n",
    "                            unique_artists.add(artist_name)\n",
    "                            unique_releases.add(release_id)\n",
    "                            artists_and_releases_and_items.add((artist_name, release_id, item_id))\n",
    "                        \n",
    "                        total_checked_items += 1  # Update total checked items after processing\n",
    "                        \n",
    "                    # Print the progress after processing each page\n",
    "                    print(f\"Checked {total_checked_items} items out of {total_items}\")\n",
    "\n",
    "            # Move to the next set of pages\n",
    "            current_page += pages_in_batch\n",
    "            pages_to_process -= pages_in_batch\n",
    "\n",
    "            # Apply adaptive sleep or wait for rate limit reset\n",
    "            if remaining_requests == 0:\n",
    "                print(f\"Rate limit reached, waiting for {reset_time} seconds...\")\n",
    "                time.sleep(reset_time)\n",
    "            else:\n",
    "                sleep_time = adaptive_sleep(remaining_requests, reset_time)\n",
    "                print(f\"Sleeping for {sleep_time:.2f} seconds to avoid hitting rate limit...\")\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "#print(f\"\\nUnique artists found in seller's inventory: {sorted(unique_artists)}\")\n",
    "print(f\"Total unique artists: {len(unique_artists)}\")\n",
    "print(f\"Total unique releases: {len(unique_releases)}\")"
   ],
   "id": "4e73ba100f173815",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items: 373, Total pages: 4\n",
      "Checked 100 items out of 373\n",
      "Checked 200 items out of 373\n",
      "Checked 273 items out of 373\n",
      "Checked 373 items out of 373\n",
      "Sleeping for 1.28 seconds to avoid hitting rate limit...\n",
      "Total unique artists: 324\n",
      "Total unique releases: 366\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3: Fetching MasterID of ReleaseIDs of each matched Artist",
   "id": "f30c00100df85146"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T10:38:12.408876Z",
     "start_time": "2024-12-22T10:38:03.747216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "time.sleep(3)\n",
    "# Find matched artists between wantlist and artists_and_releases\n",
    "matched_artists = {artist for artist, _, _ in artists_and_releases_and_items if artist in wantlist_artists}\n",
    "\n",
    "# Initialize a dictionary to store each matched artist's release IDs and master IDs\n",
    "artist_to_release_master_ids = defaultdict(lambda: {\"release_ids\": set(), \"master_ids\": set()})\n",
    "\n",
    "# Step 3: Loop through the wantlist and check for matching artists\n",
    "for item in wantlist:\n",
    "    release = item.release  # Get the release object\n",
    "    \n",
    "    # Check if any artist (with union logic) in the release matches the matched artists\n",
    "    artist_names = []\n",
    "    for artist in release.artists:\n",
    "        # Build the full artist name with the \"join\" field\n",
    "        if hasattr(artist, 'join') and artist.join:\n",
    "            artist_names.append(f\"{artist.name} {artist.join}\")\n",
    "        else:\n",
    "            artist_names.append(artist.name)\n",
    "\n",
    "    # Create a single string of all artist names in the release\n",
    "    full_artist_name = \" \".join(artist_names)\n",
    "\n",
    "    # Check if the full artist name matches any in matched_artists\n",
    "    if full_artist_name in matched_artists:\n",
    "        # Add the release ID\n",
    "        artist_to_release_master_ids[full_artist_name][\"release_ids\"].add(release.id)\n",
    "\n",
    "        # Add the master ID if it exists\n",
    "        if release.master:\n",
    "            artist_to_release_master_ids[full_artist_name][\"master_ids\"].add(release.master.id)\n",
    "\n",
    "# Print the results\n",
    "print(\"Matched artists with release and master IDs:\")\n",
    "for artist, ids in artist_to_release_master_ids.items():\n",
    "    release_ids_list = \", \".join(map(str, ids[\"release_ids\"]))\n",
    "    master_ids_list = \", \".join(map(str, ids[\"master_ids\"]))\n",
    "    print(f\"Artist: {artist}, Release IDs: {release_ids_list}, Master IDs: {master_ids_list}\")\n",
    "\n",
    "# Store distinct master IDs across all matched artists\n",
    "distinct_master_ids = set()\n",
    "for ids in artist_to_release_master_ids.values():\n",
    "    distinct_master_ids.update(ids[\"master_ids\"])\n",
    "\n",
    "# Output distinct master IDs\n",
    "print(\"\\nDistinct Master IDs:\", sorted(distinct_master_ids))\n",
    "print(\"Total distinct Master IDs:\", len(distinct_master_ids))"
   ],
   "id": "2ae977d755672003",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched artists with release and master IDs:\n",
      "Artist: Steely Dan, Release IDs: 9405826, 11462532, 2152836, 24158342, 1804939, 5805967, 8144785, 5893905, 14622867, 15422995, 16251417, 9670809, 4982428, 1710246, 13905960, 5657387, 6281645, 12955952, 15764402, 10969782, 12184375, 6956855, 16785210, 27481410, 9520450, 14482375, 1727687, 17719243, 8813003, 3228622, 4969680, 6538322, 14140630, 8887259, 2469981, 4319198, 21255265, 23386859, 3237233, 26262644, 5470198, 5098615, 1327484, 2470015, Master IDs: 17100\n",
      "Artist: Various, Release IDs: 26877272, 23640356, 7524613, 6213832, 9062153, 11000744, 478443, 13845486, 12238166, 14229974, 9409848, 3286399, Master IDs: 3188130, 1279206, 1688587, 206358, 1883259, 1736701\n",
      "Artist: Rank 1, Release IDs: 35648, 2824125, Master IDs: 73289\n",
      "Artist: Unknown Artist, Release IDs: 15837425, 15815070, 11306517, 13751577, Master IDs: \n",
      "Artist: Sade, Release IDs: 1548070, Master IDs: 43936\n",
      "Artist: Oxia, Release IDs: 6732, Master IDs: 1008401\n",
      "Artist: COEO, Release IDs: 16081637, 10800584, 9468688, 8051414, 20463514, Master IDs: 3104646, 956552, 1899759, 1242491, 1534205\n",
      "Artist: Agnelli & Nelson, Release IDs: 14538, Master IDs: 72875\n",
      "Artist: 4 Strings, Release IDs: 32027, Master IDs: 84982\n",
      "\n",
      "Distinct Master IDs: [17100, 43936, 72875, 73289, 84982, 206358, 956552, 1008401, 1242491, 1279206, 1534205, 1688587, 1736701, 1883259, 1899759, 3104646, 3188130]\n",
      "Total distinct Master IDs: 17\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 4: Fetch ReleaseID for each matched MasterID + FINAL MATCH",
   "id": "734b178b3bf15463"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T10:38:52.545202Z",
     "start_time": "2024-12-22T10:38:12.410032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "time.sleep(5)\n",
    "def fetch_master_versions(master_id, headers, per_page=100):\n",
    "    \"\"\"Fetch all release versions for a given master_id using pagination.\"\"\"\n",
    "    page = 1\n",
    "    more_pages = True\n",
    "    master_release_ids = set()  # Local set to collect each master’s release IDs\n",
    "\n",
    "    while more_pages:\n",
    "        # Construct the URL with pagination\n",
    "        url = f\"https://api.discogs.com/masters/{master_id}/versions?page={page}&per_page={per_page}&format=Vinyl\"\n",
    "        \n",
    "        # Make the API request\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            versions_data = response.json()\n",
    "            \n",
    "            # Check if there are no more items (empty page)\n",
    "            if not versions_data['versions']:\n",
    "                more_pages = False\n",
    "            else:\n",
    "                # Iterate through the versions in the response\n",
    "                for version in versions_data['versions']:\n",
    "                    release_id = version.get('id')\n",
    "                    if release_id:\n",
    "                        master_release_ids.add(release_id)\n",
    "                \n",
    "                # Move to the next page\n",
    "                page += 1\n",
    "\n",
    "            # Implement adaptive sleep based on rate limit headers\n",
    "            remaining_requests = int(response.headers.get('X-Discogs-Ratelimit-Remaining', 60))\n",
    "            reset_time = int(response.headers.get('X-Discogs-Ratelimit-Reset', 60))  # Default reset time to 60 seconds\n",
    "            if remaining_requests == 0:\n",
    "                #print(f\"Rate limit reached for master {master_id}. Waiting for {reset_time} seconds.\")\n",
    "                time.sleep(reset_time)\n",
    "            else:\n",
    "                sleep_time = max(1, reset_time / remaining_requests)  # At least 1-second sleep\n",
    "                #print(f\"Sleeping for {sleep_time:.2f} seconds between requests.\")\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "        else:\n",
    "            print(f\"Error fetching page {page} for master {master_id}: {response.status_code}, {response.text}\")\n",
    "            more_pages = False  # Stop the loop if there's an error\n",
    "\n",
    "    return master_release_ids\n",
    "\n",
    "def fetch_all_master_versions_concurrently(master_ids, headers):\n",
    "    \"\"\"Fetch release IDs for all master IDs concurrently with rate limit control.\"\"\"\n",
    "    all_masters_release_ids = set()\n",
    "    \n",
    "    # Use ThreadPoolExecutor to fetch versions for each master concurrently\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        future_to_master_id = {executor.submit(fetch_master_versions, master_id, headers): master_id for master_id in master_ids}\n",
    "        \n",
    "        # Process the results as they complete\n",
    "        for future in concurrent.futures.as_completed(future_to_master_id):\n",
    "            master_id = future_to_master_id[future]\n",
    "            try:\n",
    "                master_release_ids = future.result()\n",
    "                all_masters_release_ids.update(master_release_ids)\n",
    "                print(f\"Fetched {len(master_release_ids)} release IDs for Master ID {master_id}\")\n",
    "            except Exception as exc:\n",
    "                print(f\"Error fetching releases for Master ID {master_id}: {exc}\")\n",
    "\n",
    "    return all_masters_release_ids\n",
    "\n",
    "# Fetch all master release IDs concurrently with rate limit control\n",
    "all_masters_release_ids = fetch_all_master_versions_concurrently(distinct_master_ids, headers)\n",
    "\n",
    "\n",
    "matching_release_data = []  # To store tuples of (release_id, seller_id)\n",
    "\n",
    "for artist, release_id, seller_id in artists_and_releases_and_items:\n",
    "    if release_id in all_masters_release_ids:\n",
    "        matching_release_data.append((release_id, seller_id))\n",
    "\n",
    "# Print matching release IDs and seller IDs\n",
    "print(\"Matching Releases with Seller IDs:\")\n",
    "for release_id, seller_id in matching_release_data:\n",
    "    print(f\"Release ID: {release_id}, Seller ID: {seller_id}\")\n",
    "    print(f\"https://www.discogs.com/sell/item/{seller_id}\")\n",
    "\n",
    "# Output the count of matches\n",
    "print(f\"Total matching releases: {len(matching_release_data)}\")"
   ],
   "id": "9489839df483e3d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 2 release IDs for Master ID 3188130\n",
      "Fetched 1 release IDs for Master ID 1279206\n",
      "Fetched 83 release IDs for Master ID 43936\n",
      "Fetched 1 release IDs for Master ID 3104646\n",
      "Fetched 2 release IDs for Master ID 956552\n",
      "Fetched 15 release IDs for Master ID 73289\n",
      "Fetched 1 release IDs for Master ID 1688587\n",
      "Fetched 46 release IDs for Master ID 17100\n",
      "Fetched 18 release IDs for Master ID 72875\n",
      "Fetched 1 release IDs for Master ID 1899759\n",
      "Fetched 2 release IDs for Master ID 1008401\n",
      "Fetched 2 release IDs for Master ID 1242491\n",
      "Fetched 1 release IDs for Master ID 206358\n",
      "Fetched 30 release IDs for Master ID 84982\n",
      "Fetched 1 release IDs for Master ID 1534205\n",
      "Fetched 0 release IDs for Master ID 1736701\n",
      "Fetched 1 release IDs for Master ID 1883259\n",
      "Matching Releases with Seller IDs:\n",
      "Release ID: 14538, Seller ID: 3333581403\n",
      "https://www.discogs.com/sell/item/3333581403\n",
      "Release ID: 2222162, Seller ID: 3333769800\n",
      "https://www.discogs.com/sell/item/3333769800\n",
      "Total matching releases: 2\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
